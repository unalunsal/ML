{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tu3sKne72BS1"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "import csv\n",
        "import numpy as np  # http://www.numpy.org\n",
        "import ast\n",
        "from datetime import datetime\n",
        "from math import log, floor, ceil\n",
        "import random\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vScRPH332BTE"
      },
      "source": [
        "Modify the Utility class's methods. You can also add additional methods as required but don't change existing methods' arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLFRPEkD2BTK"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "class Utility(object):\n",
        "    \n",
        "    # This method computes entropy for information gain\n",
        "    def entropy(self, class_y):\n",
        "        entropy = 0\n",
        "        zeros = len([x for x in class_y if x == 0])\n",
        "        ones  = len([x for x in class_y if x == 1])\n",
        "        tots = len(class_y)\n",
        "        \n",
        "        if zeros > 0 and ones > 0:\n",
        "          entropy = (-1) *(zeros / tots)* (log(zeros / tots, 2)) + (-1) * (ones / tots) * (log(ones / tots, 2)) \n",
        "\n",
        "        if zeros > 0 and ones == 0:\n",
        "          entropy = (-1) *(zeros / tots)* (log(zeros / tots, 2))\n",
        "\n",
        "        if zeros == 0 and ones > 0:\n",
        "          entropy = (-1) * (ones / tots) * (log(ones / tots, 2)) \n",
        "        pass\n",
        "        return entropy\n",
        "\n",
        "\n",
        "    def partition_classes(self, X, y, split_attribute, split_val):\n",
        "\n",
        "        X_left = []\n",
        "        X_right = []\n",
        "\n",
        "        y_left = []\n",
        "        y_right = []\n",
        "\n",
        "        combos = [[x,y] for x,y in zip(X,y)]\n",
        "        combos_left = [x for x in combos if x[0][split_attribute] <= split_val]\n",
        "        combos_right = [x for x in combos if x[0][split_attribute] > split_val]\n",
        "\n",
        "        X_left = [x[0] for x in combos_left]\n",
        "        X_right = [x[0] for x in combos_right]\n",
        "\n",
        "        y_left = [x[1] for x in combos_left]\n",
        "        y_right = [x[1] for x in combos_right]\n",
        "\n",
        "        pass\n",
        "      \n",
        "        return (X_left, X_right, y_left, y_right)\n",
        "\n",
        "\n",
        "    def information_gain(self, previous_y, current_y):\n",
        "        info_gain = 0\n",
        "        current_y_left = current_y[0]\n",
        "        current_y_rigth = current_y[1]\n",
        "        leftlen  = len(current_y_left)\n",
        "        rigthlen = len(current_y_rigth)\n",
        "        totlen = leftlen + rigthlen \n",
        "\n",
        "        info_gain = self.entropy(previous_y) - (self.entropy(current_y_left) * leftlen / totlen + self.entropy(current_y_rigth) * rigthlen / totlen)\n",
        "\n",
        "        pass\n",
        "        return info_gain\n",
        "\n",
        "\n",
        "    def best_split(self, X, y):\n",
        "        split_attribute = 0\n",
        "        split_val = 0\n",
        "        X_left, X_right, y_left, y_right = [], [], [], []\n",
        "\n",
        "        colNum = len(X[0])                          # number of columns in the X\n",
        "        split_vals_all = []                         # collect each column`s unique split values\n",
        "        for i in range(0, colNum):\n",
        "          split_vals   = [x[i] for x in X]\n",
        "          split_vals_u = []\n",
        "          [split_vals_u.append(x) for x in split_vals if x not in split_vals_u]\n",
        "          split_vals_all.append(split_vals_u)       # collect each column`s uique split values\n",
        "\n",
        "        info_gains_all = []\n",
        "        for i in range(0, colNum):\n",
        "          split_vals = split_vals_all[i]\n",
        "          for split_val in split_vals:\n",
        "            (X_left, X_right, y_left, y_right) = self.partition_classes(X, y, i, split_val)\n",
        "            info_gains_all.append([X_left, X_right, y_left, y_right, self.information_gain(y, [y_left, y_right]), i, split_val])\n",
        "\n",
        "        info_gains_all.sort(key=lambda x: x[4], reverse=True) \n",
        "      \n",
        "        returnDict = {  \"split_attribute\": info_gains_all[0][5],\n",
        "                        \"split_val\": info_gains_all[0][6],\n",
        "                        \"X_left\": info_gains_all[0][0],\n",
        "                        \"X_right\": info_gains_all[0][1],\n",
        "                        \"y_left\": info_gains_all[0][2],\n",
        "                        \"y_right\": info_gains_all[0][3],\n",
        "                        \"info_gain\": info_gains_all[0][4] }\n",
        "        pass\n",
        "        return returnDict\n",
        "        #############################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8ANcnhr2BTT"
      },
      "source": [
        "### Define the classes 'DecisionTree' and 'RandomForest'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTSoTY2i2BTY"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "class DecisionTree(object):\n",
        "    def __init__(self, max_depth):\n",
        "        # Initializing the tree as an empty dictionary or list, as preferred\n",
        "        self.tree = {}\n",
        "        self.max_depth = max_depth\n",
        "        \n",
        "    \t\n",
        "    def learn(self, X, y, par_node = {}, depth=0):\n",
        "     \n",
        "        y_u = []\n",
        "        [y_u.append(x) for x in y if x not in y_u]\n",
        "        \n",
        "        if len(y_u) == 0:\n",
        "          self.tree['diagnosis'] = 0\n",
        "          return \n",
        "        elif len(y_u) == 1:\n",
        "          self.tree['diagnosis'] = y[0]\n",
        "          return\n",
        "\n",
        "\n",
        "        depth = depth + 1\n",
        "        if self.max_depth < depth:\n",
        "          return\n",
        "        \n",
        "        UtilityCall = Utility()\n",
        "        bestSplit = UtilityCall.best_split(X, y)               # splits to X_left, y_left, X_right, y_right.\n",
        "\n",
        "        self.tree['dt_left'] = DecisionTree(max_depth = self.max_depth - depth)\n",
        "        self.tree['dt_left'].learn(bestSplit['X_left'], bestSplit['y_left'])\n",
        "\n",
        "        self.tree['dt_right'] = DecisionTree(max_depth = self.max_depth - depth)\n",
        "        self.tree['dt_right'].learn(bestSplit['X_right'], bestSplit['y_right'])\n",
        "        \n",
        "        self.tree['attribute'] = bestSplit['split_attribute']\n",
        "        self.tree['value'] = bestSplit['split_val'] \n",
        "        pass\n",
        "\n",
        "\n",
        "\n",
        "    def classify(self, record):\n",
        "        treenode = self.tree\n",
        "       \n",
        "        while len(treenode) > 1:\n",
        "            treenodeAtt = treenode['attribute']\n",
        "            treenodeVal = treenode['value']\n",
        "\n",
        "            if treenodeVal >= record[treenodeAtt]:\n",
        "              treenode = treenode['dt_left'].tree\n",
        "            else:\n",
        "              treenode = treenode['dt_right'].tree\n",
        "\n",
        "        return treenode['diagnosis']         \n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYgnS_le2BTa"
      },
      "outputs": [],
      "source": [
        "class RandomForest(object):\n",
        "    num_trees = 0\n",
        "    decision_trees = []\n",
        "    bootstraps_datasets = []\n",
        "\n",
        "    bootstraps_labels = []\n",
        "\n",
        "    def __init__(self, num_trees):\n",
        "        # Initialization done here\n",
        "        self.num_trees = num_trees\n",
        "        self.decision_trees = [DecisionTree(max_depth=10) for i in range(num_trees)]\n",
        "        self.bootstraps_datasets = []\n",
        "        self.bootstraps_labels = []\n",
        "        \n",
        "    def _bootstrapping(self, XX, n):\n",
        "        sample = []                                                                # sampled dataset\n",
        "        labels = []                                                                # class labels for the sampled records\n",
        "        XXRowNums = len(XX)                                                        # number of rows in the XX. \n",
        "        randRowNums = np.random.choice(list(range(0, XXRowNums)),n)                # randomly generated row indexes  \n",
        "        \n",
        "        sample = [XX[x][:-1] for x in randRowNums]                                 # sampled dataset\n",
        "        labels = [XX[x][-1] for x in randRowNums]                                  # class labels for the sampled records            \n",
        "        pass\n",
        "        return (sample, labels)\n",
        "\n",
        "    def bootstrapping(self, XX):\n",
        "        # Initializing the bootstap datasets for each tree\n",
        "        for i in range(self.num_trees):\n",
        "            data_sample, data_label = self._bootstrapping(XX, len(XX))\n",
        "            self.bootstraps_datasets.append(data_sample)\n",
        "            self.bootstraps_labels.append(data_label)\n",
        "\n",
        "    def fitting(self):\n",
        "        [i.learn(self.bootstraps_datasets[j], self.bootstraps_labels[j]) for i,j in zip(self.decision_trees, list(range(0, len(self.decision_trees))))]       \n",
        "        pass\n",
        "\n",
        "\n",
        "    def voting(self, X):\n",
        "        y = []\n",
        "\n",
        "        for record in X:\n",
        "            votes = []\n",
        "            \n",
        "            for i in range(len(self.bootstraps_datasets)):\n",
        "                dataset = self.bootstraps_datasets[i]\n",
        "                \n",
        "                if record not in dataset:\n",
        "                    OOB_tree = self.decision_trees[i]\n",
        "                    effective_vote = OOB_tree.classify(record)\n",
        "                    votes.append(effective_vote)\n",
        "\n",
        "            counts = np.bincount(votes)\n",
        "\n",
        "            if len(counts) == 0:\n",
        "                votes = []\n",
        "                [votes.append(x.classify(record)) for x in self.decision_trees]\n",
        "\n",
        "                onesCount = len([x for x in votes if x == 1])      # number of ones\n",
        "                zerosCount = len([x for x in votes if x == 0])     # number of zeros\n",
        "                if onesCount >= zerosCount:\n",
        "                  y = np.append(y, onesCount)\n",
        "                else:\n",
        "                  y = np.append(y, zerosCount)                \n",
        "                pass\n",
        "            else:\n",
        "                y = np.append(y, np.argmax(counts))\n",
        "                \n",
        "        return y\n",
        "\n",
        "    def user(self):\n",
        "        return 'UnalUnsal'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SFwf1ku2BTf"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_forest_size():\n",
        "    forest_size = 10\n",
        "    return forest_size\n",
        "def get_random_seed():\n",
        "    random_seed = 0\n",
        "    return random_seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ble9oKKn2BTi"
      },
      "source": [
        "### Do not modify the below cell\n",
        "The cell below is provided to test that your random forest classifier can be successfully built and run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2cfUwWM2BTm"
      },
      "outputs": [],
      "source": [
        "def run():\n",
        "    np.random.seed(get_random_seed())\n",
        "    # start time \n",
        "    start = datetime.now()\n",
        "    X = list()\n",
        "    y = list()\n",
        "    XX = list()  # Contains data features and data labels\n",
        "    numerical_cols = set([i for i in range(0, 31)])  # indices of numeric attributes (columns)\n",
        "\n",
        "    # Loading data set\n",
        "    print(\"reading the data\")\n",
        "    with open(\"Wisconsin_breast_prognostic.csv\") as f:\n",
        "        next(f, None)\n",
        "        for line in csv.reader(f, delimiter=\",\"):\n",
        "            xline = []\n",
        "            for i in range(len(line)):\n",
        "                if i in numerical_cols:\n",
        "                    xline.append(ast.literal_eval(line[i]))\n",
        "                else:\n",
        "                    xline.append(line[i])\n",
        "\n",
        "            X.append(xline[:-1])\n",
        "            y.append(xline[-1])\n",
        "            XX.append(xline[:])\n",
        "\n",
        "    # Initializing a random forest.\n",
        "    randomForest = RandomForest(get_forest_size())\n",
        "\n",
        "    # printing the name\n",
        "    print(\"__Name: \" + randomForest.user()+\"__\")\n",
        "\n",
        "    # Creating the bootstrapping datasets\n",
        "    print(\"creating the bootstrap datasets\")\n",
        "    randomForest.bootstrapping(XX)\n",
        "\n",
        "    # Building trees in the forest\n",
        "    print(\"fitting the forest\")\n",
        "    randomForest.fitting()\n",
        "\n",
        "    # Calculating an unbiased error estimation of the random forest\n",
        "    # based on out-of-bag (OOB) error estimate.\n",
        "    y_predicted = randomForest.voting(X)\n",
        "\n",
        "    # Comparing predicted and true labels\n",
        "    results = [prediction == truth for prediction, truth in zip(y_predicted, y)]\n",
        "\n",
        "    # Accuracy\n",
        "    accuracy = float(results.count(True)) / float(len(results))\n",
        "\n",
        "    print(\"accuracy: %.4f\" % accuracy)\n",
        "    print(\"OOB estimate: %.4f\" % (1 - accuracy))\n",
        "\n",
        "    # end time\n",
        "    print(\"Execution time: \" + str(datetime.now() - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PoWuPZNZ2BTp"
      },
      "outputs": [],
      "source": [
        "# Call the run() function to test your implementation\n",
        "# Use this cell and any cells below for additional testing\n",
        "run()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.0 ('py3.7')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "bf1e8345f3991e63f0377349612043dc62e53d2db35e0306b2f24fb858f18319"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}